---
title: "Reading Data from the Web"
author: "AJ Catalano"
date: "11/17/2021"
output: github_document
---

```{r}
library(tidyverse)
library(rvest)
library(httr)
```

## Scraping Table from Webpage

Acquiring data from Table 1 on [this page](http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm)

```{r}
marijuana_url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"

# reading in drug use html

drug_use_html = read_html(marijuana_url)

# extracting table(s)
# look at `first` options to select different rows

marijuana_use = 
  drug_use_html %>% 
  html_nodes(css = "table") %>%
  first() %>% 
  html_table() %>%
  slice(-1) %>% 
  as_tibble()
```

## Scraping from something other than a table

Star Wars films data from [IMDb](https://www.imdb.com/list/ls070150896/)

```{r}
sw_url = "https://www.imdb.com/list/ls070150896/"

star_wars_html = read_html(sw_url)

title_vec = 
  star_wars_html %>% 
  html_nodes(css = ".lister-item-header a") %>% 
  html_text()

gross_rev_vec = 
  star_wars_html %>% 
  html_nodes(css = ".text-small:nth-child(7) span:nth-child(5)") %>% 
  html_text()

runtime_vec = 
  star_wars_html %>% 
  html_nodes(css = ".runtime") %>% 
  html_text()

starwars_df = 
  tibble(
    title = title_vec,
    gross_rev = gross_rev_vec,
    runtime = runtime_vec)
```

## water data API

```{r}
# CSV

nyc_water_csv = 
  GET("https://data.cityofnewyork.us/resource/ia2d-e54m.csv") %>% 
  content("parsed")

# JSON

nyc_water_json = 
  GET("https://data.cityofnewyork.us/resource/ia2d-e54m.json") %>% 
  content("text") %>% 
  jsonlite::fromJSON() %>% 
  as_tibble()
```

# BRFSS data

```{r}
# CSV

brfss_csv = 
  GET("https://chronicdata.cdc.gov/resource/acme-vg9e.csv") %>% 
  content("parsed")

# note that brfss_csv has 1000 rows, but the webpage dataset has 134k rows! Adjust query parameters:

brfss_csv = 
  GET("https://chronicdata.cdc.gov/resource/acme-vg9e.csv",
      query = list("$limit" = 150000)) %>% 
  content("parsed")
```

